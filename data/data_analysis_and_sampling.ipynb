{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f73a37-6962-47a5-9356-9ecba29eefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a13eae4-118a-4134-b32d-01adcdd8e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_json(\"cladder-v1-questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5f2299-c3ac-462e-a288-2d78be23a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10560 entries, 0 to 10559\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   question_id  10560 non-null  int64 \n",
      " 1   desc_id      10560 non-null  object\n",
      " 2   given_info   10560 non-null  object\n",
      " 3   question     10560 non-null  object\n",
      " 4   answer       10560 non-null  object\n",
      " 5   meta         10560 non-null  object\n",
      " 6   reasoning    8916 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 577.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>given_info</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>meta</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>alarm-mediation-nie-model1-spec1-q1</td>\n",
       "      <td>For husbands that don't set the alarm and wive...</td>\n",
       "      <td>Does husband negatively affect alarm clock thr...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                              desc_id  \\\n",
       "0           19  alarm-mediation-nie-model1-spec1-q1   \n",
       "\n",
       "                                          given_info  \\\n",
       "0  For husbands that don't set the alarm and wive...   \n",
       "\n",
       "                                            question answer  \\\n",
       "0  Does husband negatively affect alarm clock thr...     no   \n",
       "\n",
       "                                                meta  \\\n",
       "0  {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "\n",
       "                                           reasoning  \n",
       "0  {'step0': 'Let X = husband; V2 = wife; Y = ala...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.info()\n",
    "questions.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26fcb36-a79c-4aa4-9b77-4575ff9f274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1644 entries, 4 to 9078\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   question_id  1644 non-null   int64 \n",
      " 1   desc_id      1644 non-null   object\n",
      " 2   given_info   1644 non-null   object\n",
      " 3   question     1644 non-null   object\n",
      " 4   answer       1644 non-null   object\n",
      " 5   meta         1644 non-null   object\n",
      " 6   reasoning    0 non-null      object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 102.8+ KB\n"
     ]
    }
   ],
   "source": [
    "no_reasoning_qs = questions[questions[\"reasoning\"].isnull()]\n",
    "no_reasoning_qs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8818ce50-f68b-4974-aeae-e1904bbd9f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of backadj questions: 1644\n",
      "Number of questions with reasoning==None: 1644\n",
      "Overlap between these groups: 1644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of backadj questions: \" + str(sum(questions[\"meta\"].map(lambda val : val[\"query_type\"]) == 'backadj')))\n",
    "print(\"Number of questions with reasoning==None: \" + str(len(no_reasoning_qs)))\n",
    "print(\"Overlap between these groups: \" + str(sum(no_reasoning_qs[\"meta\"].map(lambda val : val[\"query_type\"]) == 'backadj')))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d76929b-2715-4356-b132-25cc161b15e3",
   "metadata": {},
   "source": [
    "All question entries with \"query_type\" equal to 'backadj' have reasoning as None- they are questions asking the LLM which of two methods should be used to try to find if there is a causal relationship between two variables in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77df19d-2683-46b1-897f-b43050f7df90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(no_reasoning_qs[\"given_info\"].map(lambda val : \"Method 1: We look\" in val and \"Method 2: We look\" in val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b71b0b-c02c-456d-9c5d-9d8b8a74f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all query_types\n",
    "qtypes = questions[\"meta\"].map(lambda val : val[\"query_type\"]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdf61a2-02a2-4eeb-9dda-f983573d8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the number of instances and associated rung for each query_type\n",
    "qtype_info = {}\n",
    "for t in qtypes:\n",
    "    t_inds = questions[\"meta\"].map(lambda val : val[\"query_type\"]) == t\n",
    "    num_q = sum(t_inds)\n",
    "    rung = int(questions.loc[t_inds][\"meta\"].map(lambda val : val[\"rung\"]).mode().values[0])\n",
    "    qtype_info[t] = (num_q, rung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f30cc8-9889-4a9c-833a-b96772ffafe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nie': (828, 3),\n",
       " 'marginal': (1644, 1),\n",
       " 'nde': (384, 3),\n",
       " 'backadj': (1644, 2),\n",
       " 'ate': (1476, 2),\n",
       " 'ett': (1296, 3),\n",
       " 'correlation': (1476, 1),\n",
       " 'collider_bias': (168, 2),\n",
       " 'exp_away': (168, 1),\n",
       " 'det-counterfactual': (1476, 3)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtype_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bce69-93c1-4be8-b501-d9629734e11d",
   "metadata": {},
   "source": [
    "Now just need to extract appropriate number of questions from each group. Ensure that they have 50% positive class breakdown like in overall dataset.\n",
    "\n",
    "Potential issue- paper mentions that the v1.0 benchmark set is primarily balanced across all stories, but the number of stories per variant (commonsense, anticommonsense, and nonsense) vary significantly, so there's an unbalanced benchmark in terms of sensicalness.\n",
    "\n",
    "CLadder has stories where the natural language description/terms were opposing the \"common sense\" intuition/interpretation/assumptions of how the scenario should work. \n",
    "\n",
    "Decision made: balance between common/anti-common/nonsense stories, try to balance story content inside those groups\n",
    "Nonsense is easy to find since desc_id starts with \"nonsense\", but need to figure out how to determine anti-common vs common sense\n",
    "\n",
    "Turns out that the way to determine common/anti-common/nonsense is to connect each question to its associated model from the meta-models.json file, using the model_id value of the question's 'meta' field. Should have realized that before but oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e860cd0a-8f26-4b4d-aabc-9e03533e332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sense-type to each question based on meta-models\n",
    "meta = pd.read_json('cladder-v1-meta-models.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b616c9e9-e126-4cad-9473-a17214a69566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7064 entries, 0 to 7063\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   model_id          7064 non-null   int64  \n",
      " 1   story_id          7064 non-null   object \n",
      " 2   graph_id          7064 non-null   object \n",
      " 3   spec_id           7064 non-null   int64  \n",
      " 4   spec              7064 non-null   object \n",
      " 5   seed              7064 non-null   int64  \n",
      " 6   builder           7064 non-null   object \n",
      " 7   difficulty        4440 non-null   object \n",
      " 8   equation_type     7064 non-null   object \n",
      " 9   background        7064 non-null   object \n",
      " 10  variable_mapping  7064 non-null   object \n",
      " 11  structure         7064 non-null   object \n",
      " 12  params            7064 non-null   object \n",
      " 13  groundtruth       7064 non-null   object \n",
      " 14  simpson           512 non-null    float64\n",
      " 15  anticommonsense   2352 non-null   object \n",
      " 16  nonsense          2360 non-null   float64\n",
      "dtypes: float64(2), int64(3), object(12)\n",
      "memory usage: 938.3+ KB\n"
     ]
    }
   ],
   "source": [
    "meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1eade0-e851-4bc2-806d-3d4f1219ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find subsets appropriately\n",
    "anticommon = meta.dropna(subset=['anticommonsense'])\n",
    "nonsense = meta.dropna(subset=['nonsense'])\n",
    "\n",
    "# Common is everything that isn't anti or non\n",
    "common = meta[~meta.isin(anticommon)].dropna(how='all')\n",
    "common = common[~common.isin(nonsense)].dropna(how='all')\n",
    "\n",
    "# Restrict to the model_ids\n",
    "anticommon = anticommon['model_id']\n",
    "nonsense = nonsense['model_id']\n",
    "common = common['model_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12803385-89f4-4178-8051-75310c77f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense(model_id):\n",
    "    '''\n",
    "    Gets the sense type (anticommon, non, common) of the provided model_id\n",
    "    '''\n",
    "    if model_id in anticommon:\n",
    "        return 'anticommonsense'\n",
    "    elif model_id in nonsense:\n",
    "        return 'nonsense'\n",
    "    else:\n",
    "        return 'commonsense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a43c05-ec5e-40c8-b9f9-689ebc5a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the sense type to each question\n",
    "questions['sense'] = questions['meta'].map(lambda val : sense(val['model_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "186ff933-8bc9-47cf-be42-f00bf08bd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down by rung first\n",
    "rungqs = {}\n",
    "num_per_rung = {}\n",
    "for i in range(1,4):\n",
    "    rungi_qs = questions[\"meta\"].map(lambda val : val[\"rung\"]) == i\n",
    "    rungqs[i] = questions.loc[rungi_qs]\n",
    "    num_per_rung[i] = sum(rungi_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fba7cc0-43cd-4f61-8004-ac7ea229a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rung 1 question types:['marginal' 'correlation' 'exp_away'] Number of questions: 3288\n",
      "Rung 2 question types:['backadj' 'ate' 'collider_bias'] Number of questions: 3288\n",
      "Rung 3 question types:['nie' 'nde' 'ett' 'det-counterfactual'] Number of questions: 3984\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    print(f\"Rung {i} question types:\" + str(rungqs[i]['meta'].map(lambda val : val['query_type']).unique()) + \" Number of questions: \"+ str(num_per_rung[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b74fac-ed52-4faa-9a9c-031a9df4f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within each rung, need to assign numbers to each qtype st total sum is 500/3 ~ 167\n",
    "#  Ideally respect approximate distributions\n",
    "total_qs = 500\n",
    "result_qs = {}\n",
    "sense_types = {'anticommonsense','nonsense','commonsense'}\n",
    "# Set RNG seed for repeatable sampling\n",
    "rng = 50288\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# loop through rungs\n",
    "for i in range(1,4):\n",
    "\n",
    "    # get the questions\n",
    "    qs = rungqs[i]\n",
    "\n",
    "    # divide and sample by sense types (went with 56 so that there's not a balancing issue with yes/no, and no jank stuff with all but one group being 57)\n",
    "    for stype in sense_types:\n",
    "        sense_qs = qs.loc[qs['sense'] == stype]\n",
    "\n",
    "        # split yes/no for even positive responses\n",
    "        s_yes_sample = sense_qs.loc[sense_qs['answer'] == 'yes'].sample(28, random_state=rng)\n",
    "        s_no_sample = sense_qs.loc[sense_qs['answer'] == 'no'].sample(28, random_state=rng)\n",
    "        dfs.append(s_yes_sample)\n",
    "        dfs.append(s_no_sample)\n",
    "        \n",
    "    \n",
    "\n",
    "# for t in qtypes:\n",
    "#     # Number of instances of the question type\n",
    "#     num_qtype = qtype_info[t][0]\n",
    "    \n",
    "#     # Rung that t belongs to\n",
    "#     rung = qtype_info[t][1]\n",
    "    \n",
    "#     # Number of qtype samples that should be extracted for balanced distribution\n",
    "#     num_to_get = math.ceil(num_qtype/num_per_rung[rung]*total_qs/3)\n",
    "    \n",
    "#     # Subset the questions DF\n",
    "#     qtype_qs = questions.loc[questions['meta'].map(lambda val : val['query_type']) == t]\n",
    "    \n",
    "#     # Split into yes and no responses\n",
    "#     t_yes = qtype_qs.loc[questions['answer'] == 'yes']\n",
    "#     t_no = qtype_qs.loc[questions['answer'] == 'no']\n",
    "    \n",
    "#     # Sample appropriately from each\n",
    "#     t_yes_sample = t_yes.sample(math.ceil(num_to_get/2), random_state=rng)\n",
    "#     t_no_sample = t_no.sample(math.ceil(num_to_get/2), random_state=rng)\n",
    "#     result_qs[t] = pd.concat([t_yes_sample, t_no_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61cfdf75-e24c-4817-96b3-ad791e61d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all DFs and output as JSON\n",
    "output = pd.concat(dfs, ignore_index=True)\n",
    "output.to_json(\"sampled_questions.json\",orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db7e437-4c2d-4422-a60d-a6cdf152c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 504 entries, 0 to 503\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   question_id  504 non-null    int64 \n",
      " 1   desc_id      504 non-null    object\n",
      " 2   given_info   504 non-null    object\n",
      " 3   question     504 non-null    object\n",
      " 4   answer       504 non-null    object\n",
      " 5   meta         504 non-null    object\n",
      " 6   reasoning    420 non-null    object\n",
      " 7   sense        504 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 31.6+ KB\n"
     ]
    }
   ],
   "source": [
    "output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d963b06e-44b3-40f1-9f46-3eab771aa981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nie': (37, 3),\n",
       " 'marginal': (76, 1),\n",
       " 'nde': (10, 3),\n",
       " 'backadj': (84, 2),\n",
       " 'ate': (70, 2),\n",
       " 'ett': (46, 3),\n",
       " 'correlation': (80, 1),\n",
       " 'collider_bias': (14, 2),\n",
       " 'exp_away': (12, 1),\n",
       " 'det-counterfactual': (75, 3)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_qtype_info = {}\n",
    "for t in qtypes:\n",
    "    t_inds = output[\"meta\"].map(lambda val : val[\"query_type\"]) == t\n",
    "    num_q = sum(t_inds)\n",
    "    rung = int(output.loc[t_inds][\"meta\"].map(lambda val : val[\"rung\"]).mode().values[0])\n",
    "    s_qtype_info[t] = (num_q, rung)\n",
    "s_qtype_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
