import argparse
import csv
import json
from pathlib import Path
from typing import Optional
import datetime
import os


def iter_jsonl(path: Path):
    """
    Read JSONL file line by line
    """
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            yield json.loads(line)


def clean_text(s: Optional[str]) -> str:
    """
    Clean and normalize text
    """
    if s is None:
        return ""
    return str(s).strip()


def call_openai_api(client, 
                    prompt: str, 
                    model: str,
                    max_tokens: int,
                    temperature: float) -> str:
    """
    Call OpenAI API and return the raw response text
    """
    try:
        request_params = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}]
        }
        
        # newer models use max_completion_tokens
        if any(x in model.lower() for x in ['gpt-5', 'o1', 'o3']):
            request_params["max_completion_tokens"] = max_tokens
        else:
            request_params["max_tokens"] = max_tokens
        
        # some models don't support temperature
        if not any(x in model.lower() for x in ['o1', 'o3', 'gpt-5']):
            request_params["temperature"] = temperature
        
        response = client.chat.completions.create(**request_params)
        
        if not response.choices:
            return "[ERROR] No choices in response"
        
        choice = response.choices[0]
        
        if not hasattr(choice, 'message'):
            return f"[ERROR] No message in choice. Choice: {choice}"
        
        if choice.message.content is None:
            return f"[ERROR] Content is None. Finish reason: {choice.finish_reason}"
        
        content = choice.message.content.strip()
        
        if not content:
            return f"[ERROR] Empty content. Finish reason: {choice.finish_reason}"
        
        return content
        
    except Exception as e:
        return f"[ERROR] {repr(e)}"


def call_anthropic_api(client, 
                       prompt: str, 
                       model: str,
                       max_tokens: int,
                       temperature: float) -> str:
    """
    Call Anthropic API and return the raw response text
    """
    try:
        message = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text.strip()
        
    except Exception as e:
        return f"[ERROR] {repr(e)}"


def initialize_client(provider: str, api_key: Optional[str] = None):
    """
    Initialize the appropriate API client based on provider
    """
    if provider == "openai":
        from openai import OpenAI
        key = api_key or os.getenv("OPENAI_API_KEY")
        if not key:
            raise ValueError(
                "OpenAI API key must be provided via --api_key argument "
                "or OPENAI_API_KEY environment variable"
            )
        return OpenAI(api_key=key)
    
    elif provider == "anthropic":
        from anthropic import Anthropic
        key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not key:
            raise ValueError(
                "Anthropic API key must be provided via --api_key argument "
                "or ANTHROPIC_API_KEY environment variable"
            )
        return Anthropic(api_key=key)
    
    else:
        raise ValueError(f"Unknown provider: {provider}. Must be 'openai' or 'anthropic'")


def get_default_model(provider: str) -> str:
    """
    Get the default model for a given provider
    """
    defaults = {
        "openai": "gpt-5-mini-2025-08-07",
        "anthropic": "claude-sonnet-4-20250514"
    }
    return defaults.get(provider, "")


def main():
    parser = argparse.ArgumentParser(
        description="Run API models (OpenAI/Anthropic) on prompts (JSONL) and export to CSV."
    )
    parser.add_argument(
        "--input_jsonl", 
        type=str, 
        default="corrupted_causal_graphs_dataset.jsonl",
        help="Input JSONL file generated by corruption.py"
    )
    parser.add_argument(
        "--output_csv", 
        type=str, 
        default="api_responses.csv",
        help="Output CSV file path"
    )
    parser.add_argument(
        "--provider",
        type=str,
        required=True,
        choices=["openai", "anthropic"],
        help="API provider to use (openai or anthropic)"
    )
    parser.add_argument(
        "--model", 
        type=str, 
        default=None,
        help="Model name. Defaults: OpenAI=gpt-5-mini-2025-08-07, Anthropic=claude-sonnet-4-20250514"
    )
    parser.add_argument(
        "--max_tokens", 
        type=int, 
        default=16384,
        help="Maximum tokens to generate (default: 16384)"
    )
    parser.add_argument(
        "--temperature", 
        type=float, 
        default=0.0,
        help="Sampling temperature (0.0 = deterministic, ignored for models that don't support it)"
    )
    parser.add_argument(
        "--limit", 
        type=int, 
        default=None,
        help="Limit number of prompts to process (for testing)"
    )
    parser.add_argument(
        "--api_key",
        type=str,
        default=None,
        help="API key (if not set via environment variable)"
    )
    
    args = parser.parse_args()

    # use default if not specified
    model = args.model or get_default_model(args.provider)
    
    client = initialize_client(args.provider, args.api_key)
    
    # pick the right api function
    if args.provider == "openai":
        api_call_func = call_openai_api
    else:
        api_call_func = call_anthropic_api
    
    input_path = Path(args.input_jsonl)
    output_path = Path(args.output_csv)

    # matches local llm output format
    fieldnames = [
        "uuid",
        "model_name",
        "response",
        "timestamp",
    ]

    count = 0
    with output_path.open("w", newline="", encoding="utf-8") as fout:
        writer = csv.DictWriter(fout, fieldnames=fieldnames)
        writer.writeheader()

        for entry in iter_jsonl(input_path):
            count += 1
            if args.limit is not None and count > args.limit:
                break

            prompt = clean_text(entry.get("prompt"))

            # Get raw response - no processing/extraction here
            # Normalization happens at analysis time via analysis_common.normalize_answer()
            response_text = api_call_func(
                client=client,
                prompt=prompt,
                model=model,
                max_tokens=args.max_tokens,
                temperature=args.temperature
            )

            row = {
                "uuid": entry.get("uuid"),
                "model_name": model,
                "response": response_text,
                "timestamp": datetime.datetime.now().isoformat(),
            }
            writer.writerow(row)

            if count % 50 == 0:
                print(f"Processed {count} rows...")

    actual_count = count if args.limit is None else min(count, args.limit)
    print(f"Done! Wrote {actual_count} rows to {output_path}")


if __name__ == "__main__":
    main()